{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d64e23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import math\n",
    "from matplotlib import patches\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import math\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import re\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout, Button\n",
    "import collections\n",
    "\n",
    "\n",
    "\n",
    "# def extract_info(filename):\n",
    "#     pattern = r\"(?P<model>.*?)_(?P<prompt>Context|NoContext)_prompt_experiment_(?P<experiment>\\d+)_temp_(?P<temp>[\\d.]+)_target_(?P<target>[\\d.]+)_.*?_Dev_Budget_(?P<budget>\\d+)_recursive_(?P<recursive>\\d+)_.*?\\.csv\"\n",
    "#     match = re.match(pattern, filename)\n",
    "#     if match:\n",
    "#         # Return a tuple as explicitly stated\n",
    "#         return (match.group('model'), match.group('prompt'), match.group('temp'), \n",
    "#           match.group('target'), int(match.group('budget')), int(match.group('recursive')))\n",
    "#     return None\n",
    "#        filename = f\"Results/LLM/{model_dropdown.value}_{prompt_value}_prompt_experiment_{experiment+1}_{current_datetime}_temp_{temp}_target_{int(targ_quant.value)}_%_Dev_Budget_{budget}_recursive_{enable_TVDL_strategy}_{timestamp}.csv\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_info(filename):\n",
    "    pattern = (\n",
    "        r\"(?P<model>[\\w\\.-]+)_\"  # Match model, including alphanumeric, dot, and dash\n",
    "        r\"(?P<prompt_value>[\\w\\.-]+)_prompt_experiment_\"  # Match prompt value\n",
    "        r\"(?P<experiment>\\d+)_temp_\"  # Match experiment number\n",
    "        r\"(?P<temp>[\\d\\.]+)_target_\"  # Match temp, allowing digits and decimal points\n",
    "        r\"(?P<target>\\d+)_%_Dev_Budget_\"  # Match target percentage\n",
    "        r\"(?P<budget>\\d+)_recursive_\"  # Match budget\n",
    "        r\"(?P<recursive>\\d+).*\\.csv$\"  # Match recursive and file ending\n",
    "    )\n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        return (match.group('model'), match.group('prompt_value'), match.group('temp'), match.group('target'), int(match.group('budget')), int(match.group('recursive')))\n",
    "\n",
    "#print(extract_info(\"gpt-3.5-turbo_Paper_info_title4_prompt_experiment_1_temp_0.0_target_99_%_Dev_Budget_4_recursive_0_1729259579.csv\"))\n",
    "\n",
    "def unique_combinations(directory):\n",
    "    unique_sets = set()\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        #print(extract_info(filename))\n",
    "        if os.path.isfile(filepath):\n",
    "            info = extract_info(filename)\n",
    "            if info:\n",
    "                unique_sets.add(info)  # This should work fine if info is a tuple\n",
    "\n",
    "    # Convert the set to a list for sorting or further operations\n",
    "    unique_list = list(unique_sets)\n",
    "    unique_list.sort(key=lambda x: (x[2], x[0]))  # Example sorting logic\n",
    "\n",
    "    return unique_list\n",
    "\n",
    "#print(unique_combinations(\"../Results/LLM\"))\n",
    "    \n",
    "\n",
    "\n",
    "def load_data(filename, budget=10):\n",
    "    df = pd.read_csv(filename)\n",
    "    strength = df['Compressive Strength'].values\n",
    "\n",
    "    if len(strength) < budget:\n",
    "        last_value = strength[-1] if len(strength) > 0 else 0\n",
    "        strength = np.pad(strength, (0, budget - len(strength)), constant_values=last_value)\n",
    "    return strength\n",
    "\n",
    "def load_data_baseline(filename, budget=10):\n",
    "    df = pd.read_csv(filename)\n",
    "    strength = df['fc_28dGroundTruth'].values\n",
    "    if len(strength) > 4:  # if more than initial samples, drop them\n",
    "        strength = strength[4:]  # drop first 4 samples\n",
    "    if len(strength) < budget:\n",
    "        last_value = strength[-1] if len(strength) > 0 else 0\n",
    "        strength = np.pad(strength, (0, budget - len(strength)), 'constant', constant_values=last_value)\n",
    "    return strength\n",
    "\n",
    "\n",
    "def load_selected_data(btn):\n",
    "    data=[]\n",
    "    for selected in combo_widget.value:\n",
    "        for file in os.listdir(selected):\n",
    "            strength = load_data(os.path.join(selected, file))\n",
    "            data.append(strength)\n",
    "    return data\n",
    "\n",
    "    print(\"Data Loaded Successfully!\")\n",
    "    \n",
    "def extract_info_baseline(filename):\n",
    "    pattern = r\"experiment_(?P<experiment>\\d+)_(?P<model>.*?)_(initialsample_(?P<initialsample>\\d+)?_)?target_(?P<target>.*?)_%_Dev_Budget_(?P<budget>\\d+)_.*\"\n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        model = match.group('model')\n",
    "        experiment = int(match.group('experiment'))\n",
    "        initial_sample_size = int(match.group('initialsample')) if match.group('initialsample') else 0\n",
    "        target = match.group('target')\n",
    "        budget = int(match.group('budget'))\n",
    "        return model, initial_sample_size, target, budget\n",
    "\n",
    "def unique_combinations_baseline(directory):\n",
    "    unique_lists = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if os.path.isfile(os.path.join(directory, filename)):\n",
    "            info = extract_info_baseline(filename)\n",
    "            if info:\n",
    "                unique_lists.append(info)\n",
    "    \n",
    "    # Sort list based on initial_sample_size (int) first, Model (str) second\n",
    "    unique_lists = list(set(unique_lists)) # Remove duplicates\n",
    "    unique_lists.sort(key=lambda x: (x[2], x[0])) # Sort\n",
    "    \n",
    "    return unique_lists\n",
    "\n",
    "#directories = ['Results/LLM','Results/BO', 'Results/RF', 'Results/RP']\n",
    "\n",
    "#directories = ['../Results/LLM','../Results/BO', '../Results/RF', '../Results/RP']\n",
    "\n",
    "# Get the relative paths of all directories in the Results folder\n",
    "def get_results_directories(base_path='Results'):\n",
    "    directories = []\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        for dir_name in dirs:\n",
    "            dir_path = os.path.relpath(os.path.join(root, dir_name))\n",
    "            directories.append(dir_path)\n",
    "    return directories\n",
    "\n",
    "# Update the directories variable\n",
    "directories = get_results_directories()\n",
    "\n",
    "#print(directories)\n",
    "# Get the unique combinations for each type of model\n",
    "unique_sets = []\n",
    "for directory in directories:\n",
    "    #if directory == 'Results/LLM':\n",
    "    if directory in directories and directory not in directories[1:4]:\n",
    "        unique_sets += unique_combinations(directory)\n",
    "    else:\n",
    "        unique_sets += unique_combinations_baseline(directory)\n",
    "\n",
    "\n",
    "# Generate the unique list\n",
    "unique_list = []\n",
    "for unique_set in unique_sets:\n",
    "    if \"gpt\" in unique_set[0]:  # For regular models\n",
    "        model, prompt, temp, target, _, prompt_chain = unique_set\n",
    "        chain_desc = \"Zero-Shot\" if prompt_chain == 0 else \"TT=3\" if prompt_chain == 1 else \"TT=5\" if prompt_chain == 2 else \"No Feedback\" if prompt_chain == 3 else prompt_chain\n",
    "        unique_list.append(f\"Model: {model}, Prompt: {prompt}, Temp: {temp}, Target: {target}, Prompt chain: {chain_desc}\")\n",
    "    else:  # For baseline models\n",
    "        model, init_samples, target, budget = unique_set\n",
    "        unique_list.append(f\"Model: {model}, Initial Samples: {init_samples}, Target: {target}, Budget: {budget}\")\n",
    "\n",
    "combo_widget = widgets.SelectMultiple(\n",
    "    #options=unique_list,\n",
    "    options=directories[1:],\n",
    "    description='Combinations:',\n",
    "    layout=Layout(width='90%', height='350px')\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# def plot_results(data, desired_target):\n",
    "    \n",
    "#     with plot_output:\n",
    "#         # Set global font sizes\n",
    "#         plt.rcParams.update({'font.size': 14})  # Adjust as needed\n",
    "#         plt.rcParams.update({'axes.titlesize': 16})  # Title font size\n",
    "#         plt.rcParams.update({'axes.labelsize': 14})  # Axis label font size\n",
    "#         plt.rcParams.update({'xtick.labelsize': 12})  # X tick label size\n",
    "#         plt.rcParams.update({'ytick.labelsize': 12})  # Y tick label size\n",
    "#         plt.rcParams.update({'legend.fontsize': 14})  # Legend font size\n",
    "        \n",
    "#         # Define the sorting key function\n",
    "#         def sorting_key(config):\n",
    "#             # Custom order for 'Information Quality'\n",
    "#             info_quality_order = {'NoContext': 0, 'Context': 1}\n",
    "#             if len(config) == 5:  # For chat models with full configuration\n",
    "#                 info_quality = config[1]\n",
    "#                 return (0, info_quality_order.get(info_quality, -1)) + config  # 0 to prioritize chat models\n",
    "#             else:  # For baseline methods, give a higher initial sort value\n",
    "#                 return (1, ) + config  # 1 to ensure baseline methods come after chat models\n",
    "\n",
    "#         # Sort the data items\n",
    "#         sorted_data = sorted(data.items(), key=lambda item: sorting_key(item[0]))\n",
    "\n",
    "#         # Group data by model, strategy, and temperature, handling different config lengths\n",
    "#         grouped_data = {}\n",
    "#         for config, strengths in sorted_data:\n",
    "#             if len(config) == 5:  # Configs with TT\n",
    "#                 group_key = tuple(config[:-1])  # Exclude the TT parameter\n",
    "#                 # Assign a string based on the value of config[-1]\n",
    "#                 tt_index = \"Zero-Shot\" if config[-1] == \"0\" else \"TT=3\" if config[-1] == \"1\" else \"TT=5\" if config[-1] == \"2\" else \"No Feedback\" if config[-1] == \"3\" else config[-1]\n",
    "#             else:  # Baseline methods\n",
    "#                 group_key = config\n",
    "#                 tt_index = \"Zero-Shot\"  # Assuming baseline is equivalent to Zero-Shot\n",
    "\n",
    "#             if group_key not in grouped_data:\n",
    "#                 grouped_data[group_key] = {\"Zero-Shot\": None, \"TT=3\": None, \"TT=5\": None,\"No Feedback\": None}  # Using strings as keys\n",
    "#             grouped_data[group_key][tt_index] = strengths\n",
    "\n",
    "#         num_configs = len(grouped_data.keys())\n",
    "#         ncols = 2\n",
    "\n",
    "#         nrows = int(math.ceil(num_configs / ncols))\n",
    "#         fig, axs = plt.subplots(nrows, ncols, figsize=(15, 5*nrows), sharex=True, sharey=True)\n",
    "        \n",
    "#         # Ensure axs is always a 2D array\n",
    "#         if nrows == 1 or ncols == 1:\n",
    "#             axs = axs.reshape(nrows, ncols)\n",
    "\n",
    "#         tt_colors = ['blue', 'green', 'pink','cyan']  # Blue for Baseline (TT=0), Orange for Increased TT (TT=1)\n",
    "\n",
    "#         y_min = np.inf\n",
    "#         y_max = -np.inf\n",
    "\n",
    "#         for idx, (config, strengths_pair) in enumerate(grouped_data.items()):\n",
    "#             row = idx // ncols\n",
    "#             col = idx % ncols\n",
    "\n",
    "#             for tt, all_strengths in enumerate(strengths_pair.values()):  # Use .values()\n",
    "#                 if all_strengths is None:\n",
    "#                     continue  # Skip if no data for this TT value\n",
    "\n",
    "#                 # Calculate cumulative max for each experiment\n",
    "#                 cumulative_strengths = [np.maximum.accumulate(strength) for strength in all_strengths]\n",
    "#                 #cumulative_strengths=all_strengths\n",
    "#                 # Calculate the mean and the 10th and 90th percentiles\n",
    "#                 mean_strengths = np.mean(cumulative_strengths, axis=0)\n",
    "#                 lower_bound = np.percentile(cumulative_strengths, 10, axis=0)\n",
    "#                 upper_bound = np.percentile(cumulative_strengths, 90, axis=0)\n",
    "\n",
    "#                 iterations = list(range(1, len(mean_strengths) + 1))\n",
    "\n",
    "#                 # Plotting\n",
    "#                 label = 'TT=5' if tt == 2 else'TT=3' if tt == 1 else \"No Feedback\" if tt == 3 else 'Zero-Shot'  \n",
    "#                 axs[row, col].plot(iterations, mean_strengths, color=tt_colors[tt], label=label, linewidth=2)\n",
    "#                 axs[row, col].fill_between(iterations, lower_bound, upper_bound, alpha=0.1, color=tt_colors[tt])\n",
    "\n",
    "#                 # Update global y-axis limits\n",
    "#                 y_min = min(y_min, lower_bound.min())\n",
    "#                 y_max = max(y_max, upper_bound.max())\n",
    "\n",
    "#             # Add labels, title, and legend for each subplot\n",
    "#             axs[row, col].set_xlabel('Development Cycle')\n",
    "#             axs[row, 0].set_ylabel('28-Day Compressive Strength - (MPa)')\n",
    "#             # Set title based on the length of config\n",
    "#             if len(config) == 4:  # For chat models with full configuration\n",
    "#                 title = f\" {'No Design Context' if {config[1]} == {'NoContext'} else 'Design Context'} \"\n",
    "                \n",
    "#                 axs[row, col].legend(loc='lower right')\n",
    "#             else:  # For baseline methods\n",
    "                \n",
    "#                 if {config[0]} == {'BO'}:\n",
    "#                     title = f\"Gaussian Process Regression\"\n",
    "#                 elif {config[0]} == {'RF'}:\n",
    "#                     title = f\"Random Forest\"\n",
    "#                 elif {config[0]} == {'RP'}:\n",
    "#                     title = f\"Random Draw\"\n",
    "#                 else:\n",
    "#                     title = f\"Baseline Method: {config[0]}\"\n",
    "            \n",
    "                    \n",
    "#             axs[row, col].set_title(title)\n",
    "#             axs[row, col].grid(True)\n",
    "            \n",
    "#             # Add horizontal line for the desired target strength\n",
    "#             axs[row, col].axhline(y=desired_target, color='r', linestyle='--')\n",
    "#             axs[row, col].set_xlim(1, 10)\n",
    "\n",
    "#         # Normalize y-axis for all subplots\n",
    "#         for ax in axs.flat:\n",
    "#             ax.set_ylim([30, 66])\n",
    "\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "def plot_results(data, desired_target): #cumulative strength\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for file in combo_widget.value:\n",
    "        filename = os.listdir(file)[0]\n",
    "        \n",
    "        pattern = (\n",
    "            r\"(?P<model>[a-zA-Z0-9.-]+(?=_))(?:_Paper_info_)?\"  # Match model, including alphanumeric, dot, and dash\n",
    "            r\"(?P<prompt_value>[\\w\\.-]+)_prompt_experiment_\"  # Match prompt value\n",
    "            r\"(?P<experiment>\\d+)_temp_\"  # Match experiment number\n",
    "            r\"(?P<temp>[\\d\\.]+)_target_\"  # Match temp\n",
    "            r\"(?P<target>\\d+)_%_Dev_Budget_\"  # Match target percentage\n",
    "            r\"(?P<budget>\\d+)_recursive_\"  # Match budget\n",
    "            r\"(?P<recursive>\\d+).*\\.csv$\"  # Match recursive and file ending\n",
    "        )\n",
    "\n",
    "        match = re.match(pattern, filename)\n",
    "    data = np.array(data) # Convert to numpy array\n",
    "    number_of_dev_cycles = len(data[0])  # Number of development cycles\n",
    "    number_of_runs = len(data)  # Number of runs\n",
    "    cumulative_values = []\n",
    "    cumulative_data = []\n",
    "    for line in data:\n",
    "        if line is None:\n",
    "            continue  # Skip if no data for this line\n",
    "\n",
    "        # Calculate cumulative max for each run\n",
    "        cumulative_strengths = np.maximum.accumulate(line)\n",
    "        cumulative_data.append(cumulative_strengths)\n",
    "     \n",
    "    cumulative_data = np.array(cumulative_data)\n",
    "    percentile_10 = np.percentile(cumulative_data, 10, axis=0)\n",
    "    percentile_90 = np.percentile(cumulative_data, 90, axis=0)\n",
    "    # Calculate the mean along the first axis (i.e., across all arrays)\n",
    "    average_array = np.mean(cumulative_data, axis=0)\n",
    "    \n",
    "    x = list(range(1, len(average_array) + 1))\n",
    "\n",
    "    plt.plot(x, average_array, linestyle='-', color='b', label=f'T = {match.group(\"temp\")}')\n",
    "    plt.axhline(y=desired_target, color='r', linestyle='--', label='Desired Target')\n",
    "    plt.xlabel('Number of Developtment Cycles')\n",
    "    plt.ylabel('Compressive Strength')\n",
    "    plt.fill_between(x, average_array, percentile_10, color='b', alpha=0.2, label='10th Percentile')\n",
    "    plt.fill_between(x, average_array, percentile_90, color='b', alpha=0.2, label='90th Percentile')\n",
    "    plt.title(f\"Cumulative: {match.group('model')} with {match.group('prompt_value')}, Runs = {number_of_runs}, Dev Cycles = {number_of_dev_cycles}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    #plt.savefig(f\"/Users/yannikmeister/Documents/Capstone_project/Results/Time=3/Cumulative:_{match.group('model')}_{match.group('prompt_value')}_Runs_{number_of_runs}_Dev_Cycles_{number_of_dev_cycles}.png\")\n",
    "\n",
    "\n",
    "\n",
    "def plot_mean_results(data, desired_target): #mean strength\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for file in combo_widget.value:\n",
    "        filename = os.listdir(file)[0]\n",
    "        \n",
    "        pattern = (\n",
    "            r\"(?P<model>[a-zA-Z0-9.-]+(?=_))(?:_Paper_info_)?\"  # Match model, including alphanumeric, dot, and dash\n",
    "            r\"(?P<prompt_value>[\\w\\.-]+)_prompt_experiment_\"  # Match prompt value\n",
    "            r\"(?P<experiment>\\d+)_temp_\"  # Match experiment number\n",
    "            r\"(?P<temp>[\\d\\.]+)_target_\"  # Match temp\n",
    "            r\"(?P<target>\\d+)_%_Dev_Budget_\"  # Match target percentage\n",
    "            r\"(?P<budget>\\d+)_recursive_\"  # Match budget\n",
    "            r\"(?P<recursive>\\d+).*\\.csv$\"  # Match recursive and file ending\n",
    "        )\n",
    "\n",
    "        match = re.match(pattern, filename)\n",
    "    data = np.array(data) # Convert to numpy array\n",
    "    #print(data)\n",
    "    number_of_dev_cycles = len(data[0])  # Number of development cycles\n",
    "    number_of_runs = len(data)  # Number of runs\n",
    "    \n",
    "    mean_data = np.mean(data, axis=0) \n",
    "    percentile_10 = np.percentile(data, 10, axis=0)\n",
    "    percentile_90 = np.percentile(data, 90, axis=0)\n",
    "\n",
    "    # print(mean_data)\n",
    "    # print(percentile_10)\n",
    "    # print(percentile_90)\n",
    "    # Calculate the mean along the first axis (i.e., across all arrays)\n",
    "    \n",
    "    x = list(range(1, len(mean_data) + 1))\n",
    "\n",
    "    plt.plot(x, mean_data, linestyle='-', color='b', label=f'T = {match.group(\"temp\")}')\n",
    "    plt.axhline(y=desired_target, color='r', linestyle='--', label='Desired Target')\n",
    "    plt.xlabel('Number of Development Cycles')\n",
    "    plt.ylabel('Compressive Strength')\n",
    "    plt.fill_between(x, mean_data, percentile_10, color='b', alpha=0.2, label='10th Percentile')\n",
    "    plt.fill_between(x, mean_data, percentile_90, color='b', alpha=0.2, label='90th Percentile')\n",
    "    plt.title(f\"Mean: {match.group('model')} with {match.group('prompt_value')}, Runs = {number_of_runs}, Dev Cycles = {number_of_dev_cycles}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    #plt.savefig(f\"/Users/yannikmeister/Documents/Capstone_project/Results/Time=3/Mean:_{match.group('model')}_{match.group('prompt_value')}_Runs_{number_of_runs}_Dev_Cycles_{number_of_dev_cycles}.png\")\n",
    "        \n",
    "# def plot_mean_results(data, desired_target):\n",
    "    \n",
    "#     with plot_output:\n",
    "#         # Set global font sizes\n",
    "#         plt.rcParams.update({'font.size': 14})  # Adjust as needed\n",
    "#         plt.rcParams.update({'axes.titlesize': 16})  # Title font size\n",
    "#         plt.rcParams.update({'axes.labelsize': 14})  # Axis label font size\n",
    "#         plt.rcParams.update({'xtick.labelsize': 12})  # X tick label size\n",
    "#         plt.rcParams.update({'ytick.labelsize': 12})  # Y tick label size\n",
    "#         plt.rcParams.update({'legend.fontsize': 14})  # Legend font size\n",
    "\n",
    "#         # Define the sorting key function\n",
    "#         def sorting_key(config):\n",
    "#             # Custom order for 'Information Quality'\n",
    "#             info_quality_order = {'NoContext': 0, 'Context': 1}\n",
    "#             if len(config) == 5:  # For chat models with full configuration\n",
    "#                 info_quality = config[1]\n",
    "#                 return (0, info_quality_order.get(info_quality, -1)) + config  # 0 to prioritize chat models\n",
    "#             else:  # For baseline methods, give a higher initial sort value\n",
    "#                 return (1, ) + config  # 1 to ensure baseline methods come after chat models\n",
    "\n",
    "#         # Sort the data items\n",
    "#         sorted_data = sorted(data.items(), key=lambda item: sorting_key(item[0]))\n",
    "\n",
    "#         # Group data by model, strategy, and temperature, handling different config lengths\n",
    "#         grouped_data = {}\n",
    "#         for config, strengths in sorted_data:\n",
    "#             if len(config) == 5:  # Configs with TT\n",
    "#                 group_key = tuple(config[:-1])  # Exclude the TT parameter\n",
    "#                 # Assign a string based on the value of config[-1]\n",
    "#                 tt_index = \"Zero-Shot\" if config[-1] == \"0\" else \"TT=3\" if config[-1] == \"1\" else \"TT=5\" if config[-1] == \"2\" else \"No Feedback\" if config[-1] == \"3\"  else config[-1]\n",
    "#             else:  # Baseline methods\n",
    "#                 group_key = config\n",
    "#                 tt_index = \"Zero-Shot\"  # Assuming baseline is equivalent to Zero-Shot\n",
    "\n",
    "#             if group_key not in grouped_data:\n",
    "#                 grouped_data[group_key] = {\"Zero-Shot\": None, \"TT=3\": None, \"TT=5\": None, \"No Feedback\": None}  # Using strings as keys\n",
    "#             grouped_data[group_key][tt_index] = strengths\n",
    "\n",
    "#         num_configs = len(grouped_data.keys())\n",
    "#         ncols = 2\n",
    "#         nrows = int(math.ceil(num_configs / ncols))\n",
    "#         fig, axs = plt.subplots(nrows, ncols, figsize=(15, 5*nrows), sharex=True, sharey=True)\n",
    "        \n",
    "#         # Ensure axs is always a 2D array\n",
    "#         if nrows == 1 or ncols == 1:\n",
    "#             axs = axs.reshape(nrows, ncols)\n",
    "\n",
    "#         tt_colors = ['blue', 'green', 'pink','cyan']  # Blue for Baseline (TT=0), Orange for Increased TT (TT=1)\n",
    "\n",
    "#         y_min = np.inf\n",
    "#         y_max = -np.inf\n",
    "\n",
    "#         for idx, (config, strengths_pair) in enumerate(grouped_data.items()):\n",
    "#             row = idx // ncols\n",
    "#             col = idx % ncols\n",
    "\n",
    "#             for tt, all_strengths in enumerate(strengths_pair.values()):  # Use .values()\n",
    "#                 if all_strengths is None:\n",
    "#                     continue  # Skip if no data for this TT value\n",
    "\n",
    "#                 # Calculate cumulative max for each experiment\n",
    "                \n",
    "        \n",
    "#                 # Calculate the mean and the 10th and 90th percentiles\n",
    "#                 mean_strengths = np.mean(all_strengths, axis=0)\n",
    "#                 lower_bound = np.percentile(all_strengths,10, axis=0)\n",
    "#                 upper_bound = np.percentile(all_strengths, 90, axis=0)\n",
    "\n",
    "#                 iterations = list(range(1, len(mean_strengths) + 1))\n",
    "\n",
    "#                 # Plotting\n",
    "#                 label = 'TT=5' if tt == 2 else'TT=3' if tt == 1 else \"No Feedback\" if tt == 3 else 'Zero-Shot'  \n",
    "#                 axs[row, col].plot(iterations, mean_strengths, color=tt_colors[tt], label=label, linewidth=2)\n",
    "#                 axs[row, col].fill_between(iterations, lower_bound, upper_bound, alpha=0.1, color=tt_colors[tt])\n",
    "\n",
    "#                 # Update global y-axis limits\n",
    "#                 y_min = min(y_min, lower_bound.min())\n",
    "#                 y_max = max(y_max, upper_bound.max())\n",
    "\n",
    "#             # Add labels, title, and legend for each subplot\n",
    "#             axs[row, col].set_xlabel('Development Cycle')\n",
    "#             axs[row, 0].set_ylabel('28-Day Compressive Strength - (MPa)')\n",
    "#             # Set title based on the length of config\n",
    "#             if len(config) == 4:  # For chat models with full configuration\n",
    "#                 title = f\" {'No Design Context' if {config[1]} == {'NoContext'} else 'Design Context'} \"\n",
    "#                 axs[row, col].legend(loc='lower right')\n",
    "#             else:  # For baseline methods\n",
    "                \n",
    "#                 if {config[0]} == {'BO'}:\n",
    "#                     title = f\"Gaussian Process Regression\"\n",
    "#                 elif {config[0]} == {'RF'}:\n",
    "#                     title = f\"Random Forest\"\n",
    "#                 elif {config[0]} == {'RP'}:\n",
    "#                     title = f\"Random Draw\"\n",
    "#                 else:\n",
    "#                     title = f\"Baseline Method: {config[0]}\"\n",
    "            \n",
    "                    \n",
    "#             axs[row, col].set_title(title)\n",
    "#             axs[row, col].grid(True)\n",
    "            \n",
    "#             # Add horizontal line for the desired target strength\n",
    "#             axs[row, col].axhline(y=desired_target, color='r', linestyle='--')\n",
    "#             axs[row, col].set_xlim(1, 10)\n",
    "\n",
    "#         # Normalize y-axis for all subplots\n",
    "#         for ax in axs.flat:\n",
    "#             ax.set_ylim([30, 66])\n",
    "\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()        \n",
    "        \n",
    "# Example usage\n",
    "# plot_results(data, desired_target)\n",
    "\n",
    "        \n",
    "import threading\n",
    "plot_output = widgets.Output()\n",
    "\n",
    "# Create a lock\n",
    "lock = threading.Lock()\n",
    "\n",
    "def on_load_and_plot(btn):\n",
    "    # Acquire the lock\n",
    "    if not lock.acquire(blocking=False):\n",
    "        print('Another session is running, please wait...')\n",
    "        return\n",
    "\n",
    "    # Clear previous plots from the Output widget\n",
    "    plot_output.clear_output(wait=True)\n",
    "\n",
    "    data = load_selected_data(btn)  # store the returned data in a variable\n",
    "\n",
    "    # Draw the new plot inside the Output widget\n",
    "    with plot_output:\n",
    "        plot_results(data, desired_target= 64.86370000000001)\n",
    "    # Release the lock\n",
    "    lock.release()\n",
    "    \n",
    "def on_load_and_plot_mean(btn):\n",
    "    # Acquire the lock\n",
    "    if not lock.acquire(blocking=False):\n",
    "        print('Another session is running, please wait...')\n",
    "        return\n",
    "\n",
    "    # Clear previous plots from the Output widget\n",
    "    plot_output.clear_output(wait=True)\n",
    "\n",
    "    data = load_selected_data(btn)  # store the returned data in a variable\n",
    "\n",
    "    # Draw the new plot inside the Output widget\n",
    "    with plot_output:\n",
    "        plot_mean_results(data, desired_target= 64.86370000000001)\n",
    "\n",
    "    # Release the lock\n",
    "    lock.release()    \n",
    "# Define the button here\n",
    "load_button = widgets.Button(description='Plot Cumulative Performance')\n",
    "load_button.on_click(on_load_and_plot)\n",
    "\n",
    "load_mean_button = widgets.Button(description='Plot Mean Performance')\n",
    "load_mean_button.on_click(on_load_and_plot_mean)\n",
    "#display(combo_widget, load_button, plot_output)\n",
    "\n",
    "##########################\n",
    "# Add Table below:\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "def show_table(data):\n",
    "    def sorting_key(config):\n",
    "        info_quality_order = {'NoContext': 0, 'Context': 1}\n",
    "        if len(config) == 5:  # For chat models with full configuration\n",
    "            return (0, info_quality_order.get(config[1], -1)) + config\n",
    "        else:  # For baseline methods\n",
    "            return (1, ) + config\n",
    "\n",
    "    def format_config_label(config):\n",
    "        if len(config) == 5:  # For chat models\n",
    "            return f\"{config[0]}, {config[1]}, TT: {config[4]}\"\n",
    "        else:  # For baseline methods\n",
    "            return f\"Baseline Method: {config[0]}\"\n",
    "\n",
    "    def highlight_max(s):\n",
    "        is_max = s == s.max()\n",
    "        return ['font-weight: bold' if v else '' for v in is_max]\n",
    "\n",
    "    def highlight_second(s):\n",
    "        ordered = s.sort_values(ascending=False)\n",
    "        if len(ordered) > 1:\n",
    "            is_second = s == ordered.iloc[1]\n",
    "        else:\n",
    "            is_second = [False] * len(s)\n",
    "        return ['text-decoration: underline' if v else '' for v in is_second]\n",
    "\n",
    "    def highlight_third(s):\n",
    "        ordered = s.sort_values(ascending=False)\n",
    "        if len(ordered) > 2:\n",
    "            is_third = s == ordered.iloc[2]\n",
    "        else:\n",
    "            is_third = [False] * len(s)\n",
    "        return ['font-style: italic' if v else '' for v in is_third]\n",
    "\n",
    "    sorted_data = sorted(data.items(), key=lambda item: sorting_key(item[0]))\n",
    "    mean_dict = {'1st': [],'2nd': [],'3rd': [],'4th': [], '5th': [],'6th': [],'7th': [],'8th': [],'9th': [], '10th': [],'Bias': [],'Variance': []}\n",
    "    lower_bound_dict =  {'1st': [],'2nd': [],'3rd': [],'4th': [], '5th': [],'6th': [],'7th': [],'8th': [],'9th': [], '10th': [],'Bias': [],'Variance': []}\n",
    "    configs = []\n",
    "    threshold = 64.86370000000001\n",
    "\n",
    "    for config, all_strengths in sorted_data:\n",
    "        label = format_config_label(config)\n",
    "        \n",
    "        configs.append(label)\n",
    "        cum_strengths = [np.maximum.accumulate(strength) for strength in all_strengths]\n",
    "        #all_strengths = all_strengths\n",
    "        mean_strengths = np.mean(cum_strengths, axis=0)\n",
    "        lower_bound = np.percentile(cum_strengths, 10, axis=0)\n",
    "        indices = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "        for i, idx in enumerate(indices):\n",
    "            mean_value = mean_strengths[idx] if idx < len(mean_strengths) else np.nan\n",
    "            lower_bound_value = lower_bound[idx] if idx < len(lower_bound) else np.nan\n",
    "            mean_dict[list(mean_dict.keys())[i]].append(mean_value)\n",
    "            lower_bound_dict[list(lower_bound_dict.keys())[i]].append(lower_bound_value)\n",
    "        \n",
    "        mean_bias = np.mean(np.mean(all_strengths, axis=0))\n",
    "        mean_lower_bound_bias = np.mean(np.percentile(all_strengths, 10, axis=0))\n",
    "        mean_dict[list(mean_dict.keys())[10]].append(mean_bias)\n",
    "        lower_bound_dict[list(lower_bound_dict.keys())[10]].append(mean_lower_bound_bias)\n",
    "        \n",
    "        mean_variance = np.std(np.mean(all_strengths, axis=0))\n",
    "        mean_lower_bound_variance = np.std(np.percentile(all_strengths, 10, axis=0))\n",
    "        mean_dict[list(mean_dict.keys())[11]].append(mean_variance)\n",
    "        lower_bound_dict[list(lower_bound_dict.keys())[11]].append(mean_lower_bound_variance)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    df_mean = pd.DataFrame(mean_dict, index=configs).applymap(lambda x: round(x, 2))\n",
    "    df_lower_bound = pd.DataFrame(lower_bound_dict, index=configs).applymap(lambda x: round(x, 2))\n",
    "\n",
    "    print(\"Mean values:\")\n",
    "    display(df_mean.style.format(\"{:.1f}\").apply(highlight_max).apply(highlight_second).apply(highlight_third))\n",
    "    print(\"Lower bound values:\")\n",
    "    display(df_lower_bound.style.format(\"{:.1f}\").apply(highlight_max).apply(highlight_second).apply(highlight_third))\n",
    " \n",
    "    df_mean.to_csv(os.path.join('Results/', 'mean_values.csv'), sep=';', decimal=',', index=True)\n",
    "    df_lower_bound.to_csv(os.path.join('Results/', 'lower_bound_values.csv'), sep=';', decimal=',', index=True)\n",
    "\n",
    "# Create a button for showing the table\n",
    "show_button = widgets.Button(description='Show Table')\n",
    "\n",
    "def on_show_table(btn):\n",
    "    # Acquire the lock\n",
    "    if not lock.acquire(blocking=False):\n",
    "        print('Another session is running, please wait...')\n",
    "        return\n",
    "\n",
    "    # Clear previous tables from the Output widget\n",
    "    table_output.clear_output(wait=True)\n",
    "\n",
    "    data = load_selected_data(btn)  # we assume that this function loads the selected data\n",
    "\n",
    "    # Draw the new table inside the Output widget\n",
    "    with table_output:\n",
    "        show_table(data)\n",
    "\n",
    "    # Release the lock\n",
    "    lock.release()\n",
    "\n",
    "show_button.on_click(on_show_table)\n",
    "\n",
    "table_output = widgets.Output()\n",
    "\n",
    "display(combo_widget, load_button,load_mean_button, plot_output, show_button, table_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657039b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
